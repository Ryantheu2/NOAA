{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries and settings\n",
    "\n",
    "#To perform array operations\n",
    "import numpy as np \n",
    "\n",
    "#Main plotting library\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from matplotlib.ticker import (AutoMinorLocator, MultipleLocator, FormatStrFormatter)\n",
    "\n",
    "#Library for accessing files in the directory\n",
    "import os\n",
    "\n",
    "#To create map projections for plots\n",
    "from cartopy import crs as ccrs\n",
    "\n",
    "#To add Basemap for mapping features\n",
    "os.environ['PROJ_LIB'] = 'C:\\\\AKH\\\\Programming\\\\basemap-master\\\\lib\\\\mpl_toolkits\\\\basemap\\\\data'\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "\n",
    "#To read in netCDF files\n",
    "from netCDF4 import Dataset\n",
    "\n",
    "#Library for using math functions\n",
    "import math\n",
    "\n",
    "#Library for collecting lists of files from folders\n",
    "import glob\n",
    "\n",
    "#Library for working with tar files\n",
    "import tarfile\n",
    "\n",
    "#Library for creating movies (animations)\n",
    "import imageio\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#Sets font size to 12\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "\n",
    "#Option to keep numpy from printing in scientific notation by default\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Work with a single file (MODIFY path, file name)\n",
    "\n",
    "#Enter file name\n",
    "fname = 'D://Data/20191025/ABI ADP/' + 'OR_ABI-L2-ADPC-M6_G17_s20192982001196_e20192982003569_c20192982004415.nc'\n",
    "\n",
    "#Set the file name to read\n",
    "file_id = Dataset(fname)\n",
    "\n",
    "#Check the contents of the entire file\n",
    "##print(file_id)\n",
    "\n",
    "#Check the \"Variables\" metadata\n",
    "##print(file_id.variables)\n",
    "\n",
    "#Check the \"Smoke\" metadata\n",
    "##print(file_id.variables['Smoke'])\n",
    "\n",
    "#Check the \"Dust\" metadata\n",
    "##print(file_id.variables['Dust'])\n",
    "\n",
    "#Check the \"DQF\" metadata\n",
    "##print(file_id.variables['DQF'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the datatype for the variables of interest\n",
    "\n",
    "print('Smoke data type is', (file_id.variables['Smoke'][:,:].dtype))\n",
    "print('Dust data type is', (file_id.variables['Dust'][:,:].dtype))\n",
    "print('DQF data type is', (file_id.variables['DQF'][:,:].dtype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select and process data from a single file\n",
    "\n",
    "#Select all of the smoke pixels using the \"Smoke\" variable\n",
    "#smoke absent = 0, smoke present = 1\n",
    "Smoke = file_id.variables['Smoke'][:,:]\n",
    "Smoke_Mask = (Smoke == 0)\n",
    "Smoke_Present = np.ma.masked_where(Smoke_Mask, Smoke)\n",
    "\n",
    "#Select all of the good quality smoke pixels using the \"DQF\" variable (bit 0)\n",
    "#good = 0, invalid = 1\n",
    "DQF = file_id.variables['DQF'][:,:]\n",
    "Smoke_Quality = ((DQF & 0) == 1)\n",
    "Smoke_Good = np.ma.masked_where(Smoke_Quality, Smoke_Present)\n",
    "\n",
    "#Select all of the pixels within valid SZA using the \"DQF\" variable (bit 7)\n",
    "#within valid SZA for smoke and dust = 0, outside of valid SZA for smoke and dust = 128\n",
    "SZA_Mask = ((DQF & 128) == 128)\n",
    "Smoke_All = np.ma.masked_where(SZA_Mask, Smoke_Good)\n",
    "\n",
    "#Subset the good quality, valid SZA smoke pixels into high-, medium-, and low-confidence using the \"DQF\" variable (bits 2-3)\n",
    "#high-confidence = 12, medium-confidence = 4, low-confidence = 0\n",
    "HC_Smoke_Mask = ((DQF & 4) & (DQF & 8) != 12)\n",
    "Smoke_HC = np.ma.masked_where(HC_Smoke_Mask, Smoke_All)\n",
    "Smoke_High = Smoke_HC + 2\n",
    "MC_Smoke_Mask = ((DQF & 4) & (DQF & 8) != 4)\n",
    "Smoke_MC = np.ma.masked_where(MC_Smoke_Mask, Smoke_All)\n",
    "Smoke_Medium = Smoke_MC + 1\n",
    "LC_Smoke_Mask = ((DQF & 4) & (DQF & 8) != 0)\n",
    "Smoke_LC = np.ma.masked_where(LC_Smoke_Mask, Smoke_All)\n",
    "Smoke_Low = Smoke_LC\n",
    "Smoke_Total = Smoke_High.filled(0) + Smoke_Medium.filled(0) + Smoke_Low.filled(0)\n",
    "\n",
    "#Select all of the dust pixels using \"Dust\" variable\n",
    "#dust absent = 0, dust present = 1\n",
    "Dust = file_id.variables['Dust'][:,:]\n",
    "Dust_Mask = (Dust == 0)\n",
    "Dust_Present = np.ma.masked_where(Dust_Mask, Dust)\n",
    "\n",
    "#Select all of the good quality dust pixels using the \"DQF\" variable (bit 1)\n",
    "#good = 0, invalid = 2\n",
    "Dust_Quality = ((DQF & 2) == 2)\n",
    "Dust_Good = np.ma.masked_where(Dust_Quality, Dust_Present)\n",
    "\n",
    "#Select all of the dust pixels outside of sun-glint using the \"DQF\" variable (bit 6)\n",
    "#outside sun-glint = 0, within sun-glint = 64\n",
    "Glint_Mask = ((DQF & 64) == 64)\n",
    "Dust_Glint = np.ma.masked_where(Glint_Mask, Dust_Good)\n",
    "\n",
    "#Select all of the pixels within valid SZA using the \"DQF\" variable (bit 7)\n",
    "Dust_All = np.ma.masked_where(SZA_Mask, Dust_Glint)\n",
    "\n",
    "#Subset the good quality dust pixels into high-, medium-, and low-confidence pixels using the \"DQF\" variable (bits 4-5)\n",
    "#high-confidence = 48, medium-confidence = 16, low-confidence = 0\n",
    "HC_Dust_Mask = ((DQF & 16) & (DQF & 32) != 48)\n",
    "Dust_HC = np.ma.masked_where(HC_Dust_Mask, Dust_All)\n",
    "Dust_High = Dust_HC + 2\n",
    "MC_Dust_Mask = ((DQF & 16) & (DQF & 32) != 16)\n",
    "Dust_MC = np.ma.masked_where(MC_Dust_Mask, Dust_All)\n",
    "Dust_Medium = Dust_MC + 1\n",
    "LC_Dust_Mask = ((DQF & 16) & (DQF & 32) != 0)\n",
    "Dust_LC = np.ma.masked_where(LC_Dust_Mask, Dust_All)\n",
    "Dust_Low = Dust_LC\n",
    "Dust_Total = Dust_High.filled(0) + Dust_Medium.filled(0) + Dust_Low.filled(0)\n",
    "\n",
    "# Algorithm to convert lat/long radian values to lat/long in degrees\n",
    "##################################################################################################################\n",
    "\n",
    "proj_info = file_id.variables['goes_imager_projection']\n",
    "lon_origin = proj_info.longitude_of_projection_origin\n",
    "H = proj_info.perspective_point_height+proj_info.semi_major_axis\n",
    "r_eq = proj_info.semi_major_axis\n",
    "r_pol = proj_info.semi_minor_axis\n",
    "\n",
    "# Data info\n",
    "lat_rad_1d = file_id.variables['x'][:]\n",
    "lon_rad_1d = file_id.variables['y'][:]\n",
    "        \n",
    "# Create meshgrid filled with radian angles\n",
    "lat_rad,lon_rad = np.meshgrid(lat_rad_1d,lon_rad_1d)\n",
    "\n",
    "# lat/lon calculus routine from satellite radian angle vectors\n",
    "lambda_0 = (lon_origin*np.pi)/180.0\n",
    "\n",
    "a_var = np.power(np.sin(lat_rad),2.0) + (np.power(np.cos(lat_rad),2.0)*(np.power(np.cos(lon_rad),2.0)+(((r_eq*r_eq)/(r_pol*r_pol))*np.power(np.sin(lon_rad),2.0))))\n",
    "b_var = -2.0*H*np.cos(lat_rad)*np.cos(lon_rad)\n",
    "c_var = (H**2.0)-(r_eq**2.0)\n",
    "\n",
    "r_s = (-1.0*b_var - np.sqrt((b_var**2)-(4.0*a_var*c_var)))/(2.0*a_var)\n",
    "\n",
    "s_x = r_s*np.cos(lat_rad)*np.cos(lon_rad)\n",
    "s_y = - r_s*np.sin(lat_rad)\n",
    "s_z = r_s*np.cos(lat_rad)*np.sin(lon_rad)\n",
    "\n",
    "Lat = (180.0/np.pi)*(np.arctan(((r_eq*r_eq)/(r_pol*r_pol))*((s_z/np.sqrt(((H-s_x)*(H-s_x))+(s_y*s_y))))))\n",
    "Lon = (lambda_0 - np.arctan(s_y/(H-s_x)))*(180.0/np.pi)\n",
    "     \n",
    "##################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Review processed data (sanity check)\n",
    "\n",
    "print('Smoke_Total maximum is', np.max(Smoke_Total), '; Smoke_Total mimimum is', np.min(Smoke_Total))\n",
    "print('Dust_Total maximum is', np.max(Dust_Total), '; Dust_Total mimimum is', np.min(Dust_Total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot aerosol detection (smoke and dust) from a single data file\n",
    "\n",
    "#Set up figure and map projection\n",
    "fig = plt.figure(figsize = (8,4))\n",
    "ax = fig.add_subplot(1,1,1, projection = ccrs.PlateCarree())\n",
    "\n",
    "#Set coastlines and national/state boundaries at low (\"l\") resolution using Basemap\n",
    "m1 = Basemap(resolution = 'l')\n",
    "m1.drawcoastlines(color = 'black')\n",
    "m1.drawcountries(color = 'black')\n",
    "m1.drawstates(color = 'white')\n",
    "m1.drawlsmask(land_color = 'grey', ocean_color = 'lightgrey', lakes = True)\n",
    "\n",
    "#Add and format title (MODIFY name)\n",
    "plt.title('GOES-17 ABI \\n Aerosol Detection \\n 20:01 UTC, 25 Oct 2019', y = 1.05, size = 15, weight = 'bold')\n",
    "\n",
    "#Zoom to coordinates\n",
    "plt.axis([-128,-64,20,52])\n",
    "\n",
    "#Create contour plot of smoke and dust data\n",
    "Plot1 = ax.contourf(Lon, Lat, Smoke_All, levels = [0.5,1.5,2.5,3.5], colors = ['hotpink', 'mediumvioletred', 'purple'])\n",
    "Plot2 = ax.contourf(Lon, Lat, Dust_All, levels = [0.5,1.5,2.5,3.5], colors =['yellow', 'sandybrown', 'sienna' ])\n",
    "\n",
    "#Add and format colorbars\n",
    "cbar1_ax = fig.add_axes([0.175, 0, 0.3, 0.05])\n",
    "cbar2_ax = fig.add_axes([0.55, 0, 0.3, 0.05])\n",
    "\n",
    "cb1 = plt.colorbar(Plot1, cax=cbar1_ax, orientation = 'horizontal', pad = 0.1)\n",
    "cb1.set_label(label = 'Smoke Confidence', size = 'large', weight = 'bold')\n",
    "cb1.ax.xaxis.set_major_formatter(ticker.NullFormatter())\n",
    "cb1.ax.xaxis.set_minor_locator(AutoMinorLocator(2))\n",
    "cb1.ax.set_xticklabels(['Low', 'Med', 'High'], minor = True, horizontalalignment='center')\n",
    "cb1.ax.tick_params(which = 'both', length=0, labelsize = 'medium')\n",
    "\n",
    "cb2 = plt.colorbar(Plot2, cax=cbar2_ax, orientation = 'horizontal', pad = 0.1)\n",
    "cb2.set_label(label = 'Dust Confidence', size = 'large', weight = 'bold')\n",
    "cb2.ax.xaxis.set_major_formatter(ticker.NullFormatter())\n",
    "cb2.ax.xaxis.set_minor_locator(AutoMinorLocator(2))\n",
    "cb2.ax.set_xticklabels(['Low', 'Med', 'High'], minor = True, horizontalalignment='center')\n",
    "cb2.ax.tick_params(which = 'both', length=0, labelsize = 'medium')\n",
    "\n",
    "#Show figure\n",
    "plt.show()\n",
    "\n",
    "#Save figure (MODIFY path, file name)\n",
    "fig.savefig('D://Data/20191025/ABI ADP/Figures/G17_ABI-ADP_20191025_2001', bbox_inches = 'tight', dpi=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make multiple individual figures of aerosol detection (one plot from each data file)\n",
    "\n",
    "#Collect all of the .nc files in given subdirectory (MODIFY path)\n",
    "file_list = sorted(glob.glob('D://Data/20191025/ABI ADP/' + '*.nc'))\n",
    "\n",
    "#Loop through data files, making/saving multiple figures, one for each data file\n",
    "for x in file_list:\n",
    "    file_id = Dataset(x)  \n",
    "    \n",
    "    #Set up figure and map projection\n",
    "    fig = plt.figure(figsize = (8,4))\n",
    "    ax = fig.add_subplot(1,1,1, projection = ccrs.PlateCarree())\n",
    "\n",
    "    #Set coastlines and national/state boundaries at low (\"l\") resolution using Basemap\n",
    "    m1 = Basemap(resolution = 'l')\n",
    "    m1.drawcoastlines(color = 'black')\n",
    "    m1.drawcountries(color = 'black')\n",
    "    m1.drawstates(color = 'white')\n",
    "    m1.drawlsmask(land_color = 'grey', ocean_color = 'lightgrey', lakes = True)\n",
    "\n",
    "    #Add and format title (MODIFY name)\n",
    "    plt.title('GOES-17 ABI \\n Aerosol Detection \\n' + x[56:58] + ':' + x[58:60] + ' UTC, 25 Oct 2019', y = 1.05, size = 15, weight = 'bold')\n",
    "\n",
    "    #Zoom to coordinates\n",
    "    plt.axis([-128,-64,20,52])\n",
    "    \n",
    "    #Select all of the smoke pixels using the \"Smoke\" variable\n",
    "    #smoke absent = 0, smoke present = 1\n",
    "    Smoke = file_id.variables['Smoke'][:,:]\n",
    "    Smoke_Mask = (Smoke == 0)\n",
    "    Smoke_Present = np.ma.masked_where(Smoke_Mask, Smoke)\n",
    "    \n",
    "    #Select all of the good quality smoke pixels using the \"DQF\" variable (bit 0)\n",
    "    #good = 0, invalid = 1\n",
    "    DQF = file_id.variables['DQF'][:,:]\n",
    "    Smoke_Quality = ((DQF & 0) == 1)\n",
    "    Smoke_Good = np.ma.masked_where(Smoke_Quality, Smoke_Present)\n",
    "    \n",
    "    #Select all of the pixels within valid SZA using the \"DQF\" variable (bit 7)\n",
    "    #within valid SZA for smoke and dust = 0, outside of valid SZA for smoke and dust = 128\n",
    "    SZA_Mask = ((DQF & 128) == 128)\n",
    "    Smoke_All = np.ma.masked_where(SZA_Mask, Smoke_Good)\n",
    "    \n",
    "    #Subset the good quality, valid SZA smoke pixels into high-, medium-, and low-confidence using the \"DQF\" variable (bits 2-3)\n",
    "    #high-confidence = 12, medium-confidence = 4, low-confidence = 0\n",
    "    HC_Smoke_Mask = ((DQF & 4) & (DQF & 8) != 12)\n",
    "    Smoke_HC = np.ma.masked_where(HC_Smoke_Mask, Smoke_All)\n",
    "    Smoke_High = Smoke_HC + 2\n",
    "    MC_Smoke_Mask = ((DQF & 4) & (DQF & 8) != 4)\n",
    "    Smoke_MC = np.ma.masked_where(MC_Smoke_Mask, Smoke_All)\n",
    "    Smoke_Medium = Smoke_MC + 1\n",
    "    LC_Smoke_Mask = ((DQF & 4) & (DQF & 8) != 0)\n",
    "    Smoke_LC = np.ma.masked_where(LC_Smoke_Mask, Smoke_All)\n",
    "    Smoke_Low = Smoke_LC\n",
    "    Smoke_Total = Smoke_High.filled(0) + Smoke_Medium.filled(0) + Smoke_Low.filled(0)\n",
    "    \n",
    "    #Select all of the dust pixels using \"Dust\" variable\n",
    "    #dust absent = 0, dust present = 1\n",
    "    Dust = file_id.variables['Dust'][:,:]\n",
    "    Dust_Mask = (Dust == 0)\n",
    "    Dust_Present = np.ma.masked_where(Dust_Mask, Dust)\n",
    "    \n",
    "    #Select all of the good quality dust pixels using the \"DQF\" variable (bit 1)\n",
    "    #good = 0, invalid = 2\n",
    "    Dust_Quality = ((DQF & 2) == 2)\n",
    "    Dust_Good = np.ma.masked_where(Dust_Quality, Dust_Present)\n",
    "    \n",
    "    #Select all of the dust pixels outside of sun-glint using the \"DQF\" variable (bit 6)\n",
    "    #outside sun-glint = 0, within sun-glint = 64\n",
    "    Glint_Mask = ((DQF & 64) == 64)\n",
    "    Dust_Glint = np.ma.masked_where(Glint_Mask, Dust_Good)\n",
    "    \n",
    "    #Select all of the pixels within valid SZA using the \"DQF\" variable (bit 7)\n",
    "    Dust_All = np.ma.masked_where(SZA_Mask, Dust_Glint)\n",
    "    \n",
    "    #Subset the good quality dust pixels into high-, medium-, and low-confidence pixels using the \"DQF\" variable (bits 4-5)\n",
    "    #high-confidence = 48, medium-confidence = 16, low-confidence = 0\n",
    "    HC_Dust_Mask = ((DQF & 16) & (DQF & 32) != 48)\n",
    "    Dust_HC = np.ma.masked_where(HC_Dust_Mask, Dust_All)\n",
    "    Dust_High = Dust_HC + 2\n",
    "    MC_Dust_Mask = ((DQF & 16) & (DQF & 32) != 16)\n",
    "    Dust_MC = np.ma.masked_where(MC_Dust_Mask, Dust_All)\n",
    "    Dust_Medium = Dust_MC + 1\n",
    "    LC_Dust_Mask = ((DQF & 16) & (DQF & 32) != 0)\n",
    "    Dust_LC = np.ma.masked_where(LC_Dust_Mask, Dust_All)\n",
    "    Dust_Low = Dust_LC\n",
    "    Dust_Total = Dust_High.filled(0) + Dust_Medium.filled(0) + Dust_Low.filled(0)\n",
    "    \n",
    "    # Algorithm to convert lat/long radian values to lat/long in degrees\n",
    "    ##################################################################################################################\n",
    "    \n",
    "    proj_info = file_id.variables['goes_imager_projection']\n",
    "    lon_origin = proj_info.longitude_of_projection_origin\n",
    "    H = proj_info.perspective_point_height+proj_info.semi_major_axis\n",
    "    r_eq = proj_info.semi_major_axis\n",
    "    r_pol = proj_info.semi_minor_axis\n",
    "    \n",
    "    # Data info\n",
    "    lat_rad_1d = file_id.variables['x'][:]\n",
    "    lon_rad_1d = file_id.variables['y'][:]\n",
    "    \n",
    "    # Create meshgrid filled with radian angles\n",
    "    lat_rad,lon_rad = np.meshgrid(lat_rad_1d,lon_rad_1d)\n",
    "    \n",
    "    # lat/lon calculus routine from satellite radian angle vectors\n",
    "    lambda_0 = (lon_origin*np.pi)/180.0\n",
    "    \n",
    "    a_var = np.power(np.sin(lat_rad),2.0) + (np.power(np.cos(lat_rad),2.0)*(np.power(np.cos(lon_rad),2.0)+(((r_eq*r_eq)/(r_pol*r_pol))*np.power(np.sin(lon_rad),2.0))))\n",
    "    b_var = -2.0*H*np.cos(lat_rad)*np.cos(lon_rad)\n",
    "    c_var = (H**2.0)-(r_eq**2.0)\n",
    "    \n",
    "    r_s = (-1.0*b_var - np.sqrt((b_var**2)-(4.0*a_var*c_var)))/(2.0*a_var)\n",
    "    \n",
    "    s_x = r_s*np.cos(lat_rad)*np.cos(lon_rad)\n",
    "    s_y = - r_s*np.sin(lat_rad)\n",
    "    s_z = r_s*np.cos(lat_rad)*np.sin(lon_rad)\n",
    "    \n",
    "    Lat = (180.0/np.pi)*(np.arctan(((r_eq*r_eq)/(r_pol*r_pol))*((s_z/np.sqrt(((H-s_x)*(H-s_x))+(s_y*s_y))))))\n",
    "    Lon = (lambda_0 - np.arctan(s_y/(H-s_x)))*(180.0/np.pi)\n",
    "    \n",
    "    ##################################################################################################################\n",
    "    \n",
    "    #Create contour plots of smoke and dust data\n",
    "    Plot1 = ax.contourf(Lon, Lat, Smoke_Total, levels = [0.5,1.5,2.5,3.5], colors = ['hotpink', 'mediumvioletred', 'purple'])\n",
    "    Plot2 = ax.contourf(Lon, Lat, Dust_Total, levels = [0.5,1.5,2.5,3.5], colors =['yellow', 'sandybrown', 'sienna' ])\n",
    "    \n",
    "    #Add and format colorbars\n",
    "    cbar1_ax = fig.add_axes([0.175, 0, 0.3, 0.05])\n",
    "    cbar2_ax = fig.add_axes([0.55, 0, 0.3, 0.05])\n",
    "    \n",
    "    cb1 = plt.colorbar(Plot1, cax=cbar1_ax, orientation = 'horizontal', pad = 0.1)\n",
    "    cb1.set_label(label = 'Smoke Confidence', size = 'large', weight = 'bold')\n",
    "    cb1.ax.xaxis.set_major_formatter(ticker.NullFormatter())\n",
    "    cb1.ax.xaxis.set_minor_locator(AutoMinorLocator(2))\n",
    "    cb1.ax.set_xticklabels(['Low', 'Med', 'High'], minor = True, horizontalalignment='center')\n",
    "    cb1.ax.tick_params(which = 'both', length=0, labelsize = 'medium')\n",
    "    \n",
    "    cb2 = plt.colorbar(Plot2, cax=cbar2_ax, orientation = 'horizontal', pad = 0.1)\n",
    "    cb2.set_label(label = 'Dust Confidence', size = 'large', weight = 'bold')\n",
    "    cb2.ax.xaxis.set_major_formatter(ticker.NullFormatter())\n",
    "    cb2.ax.xaxis.set_minor_locator(AutoMinorLocator(2))\n",
    "    cb2.ax.set_xticklabels(['Low', 'Med', 'High'], minor = True, horizontalalignment='center')\n",
    "    cb2.ax.tick_params(which = 'both', length=0, labelsize = 'medium')\n",
    "    \n",
    "    #Show figure\n",
    "    plt.show()\n",
    "    \n",
    "    #Save figure (MODIFY path, filename)\n",
    "    filename = 'G17_ABI_ADP_20191025_' + x[56:60]\n",
    "    fig.savefig('D://Data/20191025/ABI ADP/Figures/' + filename, bbox_inches = 'tight', dpi = 150)\n",
    "    \n",
    "    #Erase plot so next one can be generated\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make an animation (movie) of multiple smoke/dust figures\n",
    "\n",
    "#Collect all of the graphics files (figures) in given subdirectory (MODIFY path)\n",
    "file_list = sorted(glob.glob('D://Data/20191025/ABI ADP/Figures/' + '*.png'))\n",
    "\n",
    "#Create an empty list to store figures\n",
    "images = []\n",
    "\n",
    "#Set duration of each frame in animation (in seconds)\n",
    "duration = 1\n",
    "\n",
    "#Loop through graphics files and append to animation\n",
    "for x in file_list:\n",
    "    images.append(imageio.imread(x))\n",
    "\n",
    "#Save final animation (MODIFY path, filename)\n",
    "imageio.mimsave('D://Data/20191025/ABI ADP/Figures/ADP-Animation.gif', images, 'GIF', duration=duration)\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
